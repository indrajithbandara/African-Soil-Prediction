{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Objective **\n",
    "\n",
    "* Learn how to structure the experiments ?\n",
    "* Learn how to average models trained on different datasets only if their predictions are not correlated ?\n",
    "* How to assign weights to different models when averaging ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('poster')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy.optimize import nnls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/African_Soil_Property_Prediction/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from data import make_dataset, spectral_band_aggregated\n",
    "from models import cross_validation, eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files\n",
    "train = pd.read_csv(os.path.join(basepath, 'data/raw/training.csv'))\n",
    "test = pd.read_csv(os.path.join(basepath, 'data/raw/sorted_test.csv'))\n",
    "sample_sub = pd.read_csv(os.path.join(basepath, 'data/raw/sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create different datasets\n",
    "d1 = make_dataset.Data(train, test)\n",
    "d2 = make_dataset.Data(train, test, remove_CO2_features=True)\n",
    "d3 = spectral_band_aggregated.Data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_1, test_1 = d1.prepare()\n",
    "train_2, test_2 = d2.prepare()\n",
    "train_3, test_3 = d3.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_Ca    = train.Ca\n",
    "y_P     = train.P\n",
    "y_Sand  = train.Sand\n",
    "y_SOC   = train.SOC\n",
    "y_pH    = train.pH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split datasets into training and test set. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size' : 0.2,\n",
    "    'random_state' : 4\n",
    "}\n",
    "\n",
    "itrain, itest = cross_validation.split_dataset(len(train_1), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_Xs(X, itrain, itest):\n",
    "    X_train = X.iloc[itrain]\n",
    "    X_test  = X.iloc[itest]\n",
    "    \n",
    "    return X_train, X_test\n",
    "    \n",
    "def get_Ys(y_Ca, y_P, y_Sand, y_SOC, y_pH, itrain, itest):\n",
    "    y_train_Ca = y_Ca.iloc[itrain]\n",
    "    y_test_Ca  = y_Ca.iloc[itest]\n",
    "    \n",
    "    y_train_P  = y_P.iloc[itrain]\n",
    "    y_test_P  = y_P.iloc[itest]\n",
    "    \n",
    "    y_train_Sand  = y_Sand.iloc[itrain]\n",
    "    y_test_Sand  = y_Sand.iloc[itest]\n",
    "    \n",
    "    y_train_SOC  = y_SOC.iloc[itrain]\n",
    "    y_test_SOC  = y_SOC.iloc[itest]\n",
    "    \n",
    "    y_train_pH  = y_pH.iloc[itrain]\n",
    "    y_test_pH  = y_pH.iloc[itest]\n",
    "    \n",
    "    \n",
    "    return ([y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH],\n",
    "            [y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH])\n",
    "\n",
    "X_train_1, X_test_1 = get_Xs(train_1, itrain, itest)\n",
    "X_train_2, X_test_2 = get_Xs(train_2, itrain, itest)\n",
    "X_train_3, X_test_3 = get_Xs(train_3, itrain, itest)\n",
    "\n",
    "y_trains, y_tests = get_Ys(y_Ca, y_P, y_Sand, y_SOC, y_pH, itrain, itest)\n",
    "\n",
    "y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH = y_trains\n",
    "y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH = y_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** List of Models. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# different models\n",
    "\n",
    "pipeline_1 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_2 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_3 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_4 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_5 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_6 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_7 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_8 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_9 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_10 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_11 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "\n",
    "pipeline_12 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "\n",
    "pipeline_13 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "\n",
    "pipeline_14 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "\n",
    "pipeline_15 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Fit models. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline_1.fit(X_train_1, y_train_Ca)\n",
    "pipeline_2.fit(X_train_1, y_train_P)\n",
    "pipeline_3.fit(X_train_1, y_train_Sand)\n",
    "pipeline_4.fit(X_train_1, y_train_SOC)\n",
    "pipeline_5.fit(X_train_1, y_train_pH)\n",
    "\n",
    "pipeline_6.fit(X_train_2, y_train_Ca)\n",
    "pipeline_7.fit(X_train_2, y_train_P)\n",
    "pipeline_8.fit(X_train_2, y_train_Sand)\n",
    "pipeline_9.fit(X_train_2, y_train_SOC)\n",
    "pipeline_10.fit(X_train_2, y_train_pH)\n",
    "\n",
    "pipeline_11.fit(X_train_3, y_train_Ca)\n",
    "pipeline_12.fit(X_train_3, y_train_P)\n",
    "pipeline_13.fit(X_train_3, y_train_Sand)\n",
    "pipeline_14.fit(X_train_3, y_train_SOC)\n",
    "pipeline_15.fit(X_train_3, y_train_pH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(pipeline_1, os.path.join(basepath, 'data/processed/pipeline_train_Ca/dataset_1/model/Ca'))\n",
    "joblib.dump(pipeline_2, os.path.join(basepath, 'data/processed/pipeline_train_P/dataset_1/model/P'))\n",
    "joblib.dump(pipeline_3, os.path.join(basepath, 'data/processed/pipeline_train_Sand/dataset_1/model/Sand'))\n",
    "joblib.dump(pipeline_4, os.path.join(basepath, 'data/processed/pipeline_train_SOC/dataset_1/model/SOC'))\n",
    "joblib.dump(pipeline_5, os.path.join(basepath, 'data/processed/pipeline_train_pH/dataset_1/model/pH'))\n",
    "\n",
    "joblib.dump(pipeline_6, os.path.join(basepath, 'data/processed/pipeline_train_Ca/dataset_2/model/Ca'))\n",
    "joblib.dump(pipeline_7, os.path.join(basepath, 'data/processed/pipeline_train_P/dataset_2/model/P'))\n",
    "joblib.dump(pipeline_8, os.path.join(basepath, 'data/processed/pipeline_train_Sand/dataset_2/model/Sand'))\n",
    "joblib.dump(pipeline_9, os.path.join(basepath, 'data/processed/pipeline_train_SOC/dataset_2/model/SOC'))\n",
    "joblib.dump(pipeline_10, os.path.join(basepath, 'data/processed/pipeline_train_pH/dataset_2/model/pH'))\n",
    "\n",
    "joblib.dump(pipeline_11, os.path.join(basepath, 'data/processed/pipeline_train_Ca/dataset_3/model/Ca'))\n",
    "joblib.dump(pipeline_12, os.path.join(basepath, 'data/processed/pipeline_train_P/dataset_3/model/P'))\n",
    "joblib.dump(pipeline_13, os.path.join(basepath, 'data/processed/pipeline_train_Sand/dataset_3/model/Sand'))\n",
    "joblib.dump(pipeline_14, os.path.join(basepath, 'data/processed/pipeline_train_SOC/dataset_3/model/SOC'))\n",
    "joblib.dump(pipeline_15, os.path.join(basepath, 'data/processed/pipeline_train_pH/dataset_3/model/pH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_dataset_1_Ca    = pipeline_1.predict(X_test_1)\n",
    "y_dataset_1_P     = pipeline_2.predict(X_test_1)\n",
    "y_dataset_1_Sand  = pipeline_3.predict(X_test_1)\n",
    "y_dataset_1_SOC   = pipeline_4.predict(X_test_1)\n",
    "y_dataset_1_pH    = pipeline_5.predict(X_test_1)\n",
    "\n",
    "y_dataset_2_Ca    = pipeline_6.predict(X_test_2)\n",
    "y_dataset_2_P     = pipeline_7.predict(X_test_2)\n",
    "y_dataset_2_Sand  = pipeline_8.predict(X_test_2)\n",
    "y_dataset_2_SOC   = pipeline_9.predict(X_test_2)\n",
    "y_dataset_2_pH    = pipeline_10.predict(X_test_2)\n",
    "\n",
    "y_dataset_3_Ca    = pipeline_11.predict(X_test_3)\n",
    "y_dataset_3_P     = pipeline_12.predict(X_test_3)\n",
    "y_dataset_3_Sand  = pipeline_13.predict(X_test_3)\n",
    "y_dataset_3_SOC   = pipeline_14.predict(X_test_3)\n",
    "y_dataset_3_pH    = pipeline_15.predict(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(y_dataset_1_Ca, os.path.join(basepath, 'data/processed/pipeline_train_Ca/dataset_1/predictions/Ca'))\n",
    "joblib.dump(y_dataset_1_P, os.path.join(basepath, 'data/processed/pipeline_train_P/dataset_1/predictions/P'))\n",
    "joblib.dump(y_dataset_1_Sand, os.path.join(basepath, 'data/processed/pipeline_train_Sand/dataset_1/predictions/Sand'))\n",
    "joblib.dump(y_dataset_1_SOC, os.path.join(basepath, 'data/processed/pipeline_train_SOC/dataset_1/predictions/SOC'))\n",
    "joblib.dump(y_dataset_1_pH, os.path.join(basepath, 'data/processed/pipeline_train_pH/dataset_1/predictions/pH'))\n",
    "\n",
    "joblib.dump(y_dataset_2_Ca, os.path.join(basepath, 'data/processed/pipeline_train_Ca/dataset_2/predictions/Ca'))\n",
    "joblib.dump(y_dataset_2_P, os.path.join(basepath, 'data/processed/pipeline_train_P/dataset_2/predictions/P'))\n",
    "joblib.dump(y_dataset_2_Sand, os.path.join(basepath, 'data/processed/pipeline_train_Sand/dataset_2/predictions/Sand'))\n",
    "joblib.dump(y_dataset_2_SOC, os.path.join(basepath, 'data/processed/pipeline_train_SOC/dataset_2/predictions/SOC'))\n",
    "joblib.dump(y_dataset_2_pH, os.path.join(basepath, 'data/processed/pipeline_train_pH/dataset_2/predictions/pH'))\n",
    "\n",
    "joblib.dump(y_dataset_3_Ca, os.path.join(basepath, 'data/processed/pipeline_train_Ca/dataset_3/predictions/Ca'))\n",
    "joblib.dump(y_dataset_3_P, os.path.join(basepath, 'data/processed/pipeline_train_P/dataset_3/predictions/P'))\n",
    "joblib.dump(y_dataset_3_Sand, os.path.join(basepath, 'data/processed/pipeline_train_Sand/dataset_3/predictions/Sand'))\n",
    "joblib.dump(y_dataset_3_SOC, os.path.join(basepath, 'data/processed/pipeline_train_SOC/dataset_3/predictions/SOC'))\n",
    "joblib.dump(y_dataset_3_pH, os.path.join(basepath, 'data/processed/pipeline_train_pH/dataset_3/predictions/pH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load predictions from disk\n",
    "\n",
    "y_dataset_1_Ca   = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_Ca/dataset_1/predictions/Ca'))\n",
    "y_dataset_1_P    = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_P/dataset_1/predictions/P'))\n",
    "y_dataset_1_Sand = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_Sand/dataset_1/predictions/Sand'))\n",
    "y_dataset_1_SOC  = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_SOC/dataset_1/predictions/SOC'))\n",
    "y_dataset_1_pH   = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_pH/dataset_1/predictions/pH'))\n",
    "\n",
    "y_dataset_2_Ca   = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_Ca/dataset_2/predictions/Ca'))\n",
    "y_dataset_2_P    = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_P/dataset_2/predictions/P'))\n",
    "y_dataset_2_Sand = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_Sand/dataset_2/predictions/Sand'))\n",
    "y_dataset_2_SOC  = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_SOC/dataset_2/predictions/SOC'))\n",
    "y_dataset_2_pH   = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_pH/dataset_2/predictions/pH'))\n",
    "\n",
    "y_dataset_3_Ca   = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_Ca/dataset_3/predictions/Ca'))\n",
    "y_dataset_3_P    = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_P/dataset_3/predictions/P'))\n",
    "y_dataset_3_Sand = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_Sand/dataset_3/predictions/Sand'))\n",
    "y_dataset_3_SOC  = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_SOC/dataset_3/predictions/SOC'))\n",
    "y_dataset_3_pH   = joblib.load(os.path.join(basepath, 'data/processed/pipeline_train_pH/dataset_3/predictions/pH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_selected(data, labels):\n",
    "    weights, _ = nnls(data[:len(labels)], labels)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_Ca = np.vstack([y_dataset_1_Ca, y_dataset_2_Ca, y_dataset_3_Ca]).T\n",
    "preds_P = np.vstack([y_dataset_1_P, y_dataset_2_P, y_dataset_3_P]).T\n",
    "preds_Sand = np.vstack([y_dataset_1_Sand, y_dataset_2_Sand, y_dataset_3_Sand]).T\n",
    "preds_SOC = np.vstack([y_dataset_1_SOC, y_dataset_2_SOC, y_dataset_3_SOC]).T\n",
    "preds_pH = np.vstack([y_dataset_1_pH, y_dataset_2_pH, y_dataset_3_pH]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_Ca = weight_selected(preds_Ca, y_test_Ca)\n",
    "weights_P = weight_selected(preds_P, y_test_P)\n",
    "weights_Sand = weight_selected(preds_Sand, y_test_Sand)\n",
    "weights_SOC = weight_selected(preds_SOC, y_test_SOC)\n",
    "weights_pH = weight_selected(preds_pH, y_test_pH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "balanced_pred_Ca = preds_Ca[:, weights_Ca > 0].mean(axis=1)[:len(y_test_Ca)]\n",
    "balanced_pred_P = preds_P[:, weights_P > 0].mean(axis=1)[:len(y_test_P)]\n",
    "balanced_pred_Sand = preds_Sand[:, weights_Sand > 0].mean(axis=1)[:len(y_test_Sand)]\n",
    "balanced_pred_SOC = preds_SOC[:, weights_SOC > 0].mean(axis=1)[:len(y_test_SOC)]\n",
    "balanced_pred_pH = preds_pH[:, weights_pH > 0].mean(axis=1)[:len(y_test_pH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE after balancing: 0.412842\n"
     ]
    }
   ],
   "source": [
    "print('MCRMSE after balancing: %f' %(eval_metric.mcrmse([y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH],\n",
    "                                                 [balanced_pred_Ca, balanced_pred_P, balanced_pred_Sand, balanced_pred_SOC,\n",
    "                                                  balanced_pred_pH])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training on full dataset. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_1.fit(train_1, y_Ca)\n",
    "pipeline_2.fit(train_1, y_P)\n",
    "pipeline_3.fit(train_1, y_Sand)\n",
    "pipeline_4.fit(train_1, y_SOC)\n",
    "pipeline_5.fit(train_1, y_pH)\n",
    "\n",
    "pipeline_6.fit(train_2, y_Ca)\n",
    "pipeline_7.fit(train_2, y_P)\n",
    "pipeline_8.fit(train_2, y_Sand)\n",
    "pipeline_9.fit(train_2, y_SOC)\n",
    "pipeline_10.fit(train_2, y_pH)\n",
    "\n",
    "pipeline_11.fit(train_3, y_Ca)\n",
    "pipeline_12.fit(train_3, y_P)\n",
    "pipeline_13.fit(train_3, y_Sand)\n",
    "pipeline_14.fit(train_3, y_SOC)\n",
    "pipeline_15.fit(train_3, y_pH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH_01.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH_02.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH_03.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH_04.npy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline_1, os.path.join(basepath, 'data/processed/pipeline_full_Ca/dataset_1/model/Ca'))\n",
    "joblib.dump(pipeline_2, os.path.join(basepath, 'data/processed/pipeline_full_P/dataset_1/model/P'))\n",
    "joblib.dump(pipeline_3, os.path.join(basepath, 'data/processed/pipeline_full_Sand/dataset_1/model/Sand'))\n",
    "joblib.dump(pipeline_4, os.path.join(basepath, 'data/processed/pipeline_full_SOC/dataset_1/model/SOC'))\n",
    "joblib.dump(pipeline_5, os.path.join(basepath, 'data/processed/pipeline_full_pH/dataset_1/model/pH'))\n",
    "\n",
    "joblib.dump(pipeline_6, os.path.join(basepath, 'data/processed/pipeline_full_Ca/dataset_2/model/Ca'))\n",
    "joblib.dump(pipeline_7, os.path.join(basepath, 'data/processed/pipeline_full_P/dataset_2/model/P'))\n",
    "joblib.dump(pipeline_8, os.path.join(basepath, 'data/processed/pipeline_full_Sand/dataset_2/model/Sand'))\n",
    "joblib.dump(pipeline_9, os.path.join(basepath, 'data/processed/pipeline_full_SOC/dataset_2/model/SOC'))\n",
    "joblib.dump(pipeline_10, os.path.join(basepath, 'data/processed/pipeline_full_pH/dataset_2/model/pH'))\n",
    "\n",
    "joblib.dump(pipeline_11, os.path.join(basepath, 'data/processed/pipeline_full_Ca/dataset_3/model/Ca'))\n",
    "joblib.dump(pipeline_12, os.path.join(basepath, 'data/processed/pipeline_full_P/dataset_3/model/P'))\n",
    "joblib.dump(pipeline_13, os.path.join(basepath, 'data/processed/pipeline_full_Sand/dataset_3/model/Sand'))\n",
    "joblib.dump(pipeline_14, os.path.join(basepath, 'data/processed/pipeline_full_SOC/dataset_3/model/SOC'))\n",
    "joblib.dump(pipeline_15, os.path.join(basepath, 'data/processed/pipeline_full_pH/dataset_3/model/pH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dataset_1_Ca    = pipeline_1.predict(test_1)\n",
    "y_dataset_1_P     = pipeline_2.predict(test_1)\n",
    "y_dataset_1_Sand  = pipeline_3.predict(test_1)\n",
    "y_dataset_1_SOC   = pipeline_4.predict(test_1)\n",
    "y_dataset_1_pH    = pipeline_5.predict(test_1)\n",
    "\n",
    "y_dataset_2_Ca    = pipeline_6.predict(test_2)\n",
    "y_dataset_2_P     = pipeline_7.predict(test_2)\n",
    "y_dataset_2_Sand  = pipeline_8.predict(test_2)\n",
    "y_dataset_2_SOC   = pipeline_9.predict(test_2)\n",
    "y_dataset_2_pH    = pipeline_10.predict(test_2)\n",
    "\n",
    "y_dataset_3_Ca    = pipeline_11.predict(test_3)\n",
    "y_dataset_3_P     = pipeline_12.predict(test_3)\n",
    "y_dataset_3_Sand  = pipeline_13.predict(test_3)\n",
    "y_dataset_3_SOC   = pipeline_14.predict(test_3)\n",
    "y_dataset_3_pH    = pipeline_15.predict(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_Ca = np.vstack([y_dataset_1_Ca, y_dataset_2_Ca, y_dataset_3_Ca]).T\n",
    "preds_P = np.vstack([y_dataset_1_P, y_dataset_2_P, y_dataset_3_P]).T\n",
    "preds_Sand = np.vstack([y_dataset_1_Sand, y_dataset_2_Sand, y_dataset_3_Sand]).T\n",
    "preds_SOC = np.vstack([y_dataset_1_SOC, y_dataset_2_SOC, y_dataset_3_SOC]).T\n",
    "preds_pH = np.vstack([y_dataset_1_pH, y_dataset_2_pH, y_dataset_3_pH]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_pred_Ca = preds_Ca[:, weights_Ca > 0].mean(axis=1)[:len(y_Ca)]\n",
    "balanced_pred_P = preds_P[:, weights_P > 0].mean(axis=1)[:len(y_P)]\n",
    "balanced_pred_Sand = preds_Sand[:, weights_Sand > 0].mean(axis=1)[:len(y_Sand)]\n",
    "balanced_pred_SOC = preds_SOC[:, weights_SOC > 0].mean(axis=1)[:len(y_SOC)]\n",
    "balanced_pred_pH = preds_pH[:, weights_pH > 0].mean(axis=1)[:len(y_pH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub['Ca']   = balanced_pred_Ca\n",
    "sample_sub['P']    = balanced_pred_P\n",
    "sample_sub['pH']   = balanced_pred_pH\n",
    "sample_sub['SOC']  = balanced_pred_SOC\n",
    "sample_sub['Sand'] = balanced_pred_Sand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Public Leaderboard Score: 0.49149 , Private Leaderboard Score: 0.53293 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub.to_csv(os.path.join(basepath, 'submissions/average_models.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
