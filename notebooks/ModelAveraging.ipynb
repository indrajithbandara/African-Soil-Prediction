{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Objective **\n",
    "\n",
    "* Learn how to structure the experiments ?\n",
    "* Learn how to average models trained on different datasets only if their predictions are not correlated ?\n",
    "* How to assign weights to different models when averaging ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('poster')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/African_Soil_Property_Prediction/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from data import make_dataset, spectral_band_aggregated\n",
    "from models import cross_validation, eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files\n",
    "train = pd.read_csv(os.path.join(basepath, 'data/raw/training.csv'))\n",
    "test = pd.read_csv(os.path.join(basepath, 'data/raw/sorted_test.csv'))\n",
    "sample_sub = pd.read_csv(os.path.join(basepath, 'data/raw/sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create different datasets\n",
    "d1 = make_dataset.Data(train, test)\n",
    "d2 = make_dataset.Data(train, test, remove_CO2_features=True)\n",
    "d3 = spectral_band_aggregated.Data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_1, test_1 = d1.prepare()\n",
    "train_2, test_2 = d2.prepare()\n",
    "train_3, test_3 = d3.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_Ca    = train.Ca\n",
    "y_P     = train.P\n",
    "y_Sand  = train.Sand\n",
    "y_SOC   = train.SOC\n",
    "y_pH    = train.pH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split datasets into training and test set. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size' : 0.2,\n",
    "    'random_state' : 4\n",
    "}\n",
    "\n",
    "itrain, itest = cross_validation.split_dataset(len(train_1), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_Xs(X, itrain, itest):\n",
    "    X_train = X.iloc[itrain]\n",
    "    X_test  = X.iloc[itest]\n",
    "    \n",
    "    return X_train, X_test\n",
    "    \n",
    "def get_Ys(y_Ca, y_P, y_Sand, y_SOC, y_pH, itrain, itest):\n",
    "    y_train_Ca = y_Ca.iloc[itrain]\n",
    "    y_test_Ca  = y_Ca.iloc[itest]\n",
    "    \n",
    "    y_train_P  = y_P.iloc[itrain]\n",
    "    y_test_P  = y_P.iloc[itest]\n",
    "    \n",
    "    y_train_Sand  = y_Sand.iloc[itrain]\n",
    "    y_test_Sand  = y_Sand.iloc[itest]\n",
    "    \n",
    "    y_train_SOC  = y_SOC.iloc[itrain]\n",
    "    y_test_SOC  = y_SOC.iloc[itest]\n",
    "    \n",
    "    y_train_pH  = y_pH.iloc[itrain]\n",
    "    y_test_pH  = y_pH.iloc[itest]\n",
    "    \n",
    "    \n",
    "    return ([y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH],\n",
    "            [y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH])\n",
    "\n",
    "X_train_1, X_test_1 = get_Xs(train_1, itrain, itest)\n",
    "X_train_2, X_test_2 = get_Xs(train_2, itrain, itest)\n",
    "X_train_3, X_test_3 = get_Xs(train_3, itrain, itest)\n",
    "\n",
    "y_trains, y_tests = get_Ys(y_Ca, y_P, y_Sand, y_SOC, y_pH, itrain, itest)\n",
    "\n",
    "y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH = y_trains\n",
    "y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH = y_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Model Library. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelLibrary:\n",
    "    \n",
    "    def __init__(self, pipelines, dataset_name):\n",
    "        self.pipelines = pipelines\n",
    "        self.dataset_name = dataset_name\n",
    "        \n",
    "        self.index_dict = {\n",
    "            'Ca': 0,\n",
    "            'P': 1,\n",
    "            'Sand': 2,\n",
    "            'SOC': 3,\n",
    "            'pH': 4\n",
    "        }\n",
    "        \n",
    "    def map_indexes_by_label(self, label):\n",
    "        return self.index_dict[label]\n",
    "    \n",
    "    def get_model_by_label(self, label):\n",
    "        model_index = self.map_indexes_by_label(label)\n",
    "        \n",
    "        return self.pipelines[model_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# different models\n",
    "\n",
    "pipeline_1 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_2 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_3 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_4 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_5 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=100)),\n",
    "        ('model', SVR(kernel='linear'))\n",
    "    ])\n",
    "\n",
    "pipeline_6 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "\n",
    "pipeline_7 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "\n",
    "pipeline_8 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "\n",
    "pipeline_9 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "\n",
    "pipeline_10 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_dataset_1 = ModelLibrary([pipeline_1, pipeline_2, pipeline_3, pipeline_4, pipeline_5], 'dataset_1')\n",
    "ml_dataset_2 = ModelLibrary([pipeline_1, pipeline_2, pipeline_3, pipeline_4, pipeline_5], 'dataset_2')\n",
    "ml_dataset_3 = ModelLibrary([pipeline_6, pipeline_7, pipeline_8, pipeline_9, pipeline_10], 'dataset_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelAveraging:\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.ml_libraries = params['ml_libraries']\n",
    "        \n",
    "        self.datasets = {\n",
    "            'dataset_1': (params['X_train_1'], params['X_test_1']),\n",
    "            'dataset_2': (params['X_train_2'], params['X_test_2']),\n",
    "            'dataset_3': (params['X_train_3'], params['X_test_3'])\n",
    "        }\n",
    "        \n",
    "        self.labels = {\n",
    "            'Ca': (params['y_train_Ca'], params['y_test_Ca']),\n",
    "            'P': (params['y_train_P'], params['y_test_P']),\n",
    "            'Sand': (params['y_train_Sand'], params['y_test_Sand']),\n",
    "            'SOC': (params['y_train_SOC'], params['y_test_SOC']),\n",
    "            'pH': (params['y_train_pH'], params['y_test_pH'])\n",
    "        }\n",
    "        \n",
    "    def get_predictions(self):\n",
    "        \"\"\"\n",
    "        For every label train a model on the training set\n",
    "        on a given dataset\n",
    "        \"\"\"\n",
    "        predictions = {}\n",
    "        datasets = ['dataset_1', 'dataset_2', 'dataset_3']\n",
    "        labels = ['Ca', 'P', 'Sand', 'SOC', 'pH']\n",
    "        \n",
    "        for dataset_name in datasets:\n",
    "            predictions[dataset_name] = {}\n",
    "            Xtr, Xte = self.datasets[dataset_name]\n",
    "            \n",
    "            for label in labels:\n",
    "                ytr, yte = self.labels[label]\n",
    "                \n",
    "                for ml in self.ml_libraries:\n",
    "                    if ml.dataset_name == dataset_name:\n",
    "                        model = ml.get_model_by_label(label)\n",
    "                        \n",
    "                        model.fit(Xtr, ytr)\n",
    "                        ypred = model.predict(Xte)\n",
    "                        \n",
    "                        predictions[dataset_name][label] = ypred\n",
    "        \n",
    "        self.predictions = predictions\n",
    "        \n",
    "        return self.predictions\n",
    "    \n",
    "    def get_mcrmse(self):\n",
    "        y_test = [self.labels[label][1] for label in ['Ca', 'P', 'Sand', 'SOC', 'pH']]\n",
    "        \n",
    "        for k, v in self.predictions.items():\n",
    "            y_pred = [v[key] for key in ['Ca', 'P', 'Sand', 'SOC', 'pH']]\n",
    "            \n",
    "            print('For: %s'%k)\n",
    "            print('MCRMSE: %f'%eval_metric.mcrmse(y_test, y_pred))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'ml_libraries': [ml_dataset_1, ml_dataset_2, ml_dataset_3],\n",
    "    'X_train_1': X_train_1,\n",
    "    'X_test_1': X_test_1,\n",
    "    'X_train_2': X_train_2,\n",
    "    'X_test_2': X_test_2,\n",
    "    'X_train_3': X_train_3,\n",
    "    'X_test_3': X_test_3,\n",
    "    'y_train_Ca': y_train_Ca,\n",
    "    'y_test_Ca': y_test_Ca,\n",
    "    'y_train_P': y_train_P,\n",
    "    'y_test_P': y_test_P,\n",
    "    'y_train_Sand': y_train_Sand,\n",
    "    'y_test_Sand': y_test_Sand,\n",
    "    'y_train_SOC': y_train_SOC,\n",
    "    'y_test_SOC': y_test_SOC,\n",
    "    'y_train_pH': y_train_pH,\n",
    "    'y_test_pH': y_test_pH\n",
    "}\n",
    "\n",
    "ma = ModelAveraging(**params)\n",
    "predictions = ma.get_predictions()\n",
    "ma.get_mcrmse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
