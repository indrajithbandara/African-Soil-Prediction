{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Objectives **\n",
    "\n",
    "* Find balanced predictions across different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/African_Soil_Property_Prediction/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "from helper import utils\n",
    "from models import eval_metric, cross_validation, find_weights, models_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(basepath, 'data/raw/training.csv'))\n",
    "sample_sub = pd.read_csv(os.path.join(basepath, 'data/raw/sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_Ca, y_P, y_Sand, y_SOC, y_pH = utils.define_target_variables(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load dataset files based on the dataset. \n",
    "* Split into training and test set if cv mode is on\n",
    "* predictions on the test set\n",
    "* if cv mode is on, then find weights, balance predictions and dump weights\n",
    "* else load weights and balance predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Averaging:\n",
    "    labels = ['Ca', 'P', 'Sand', 'SOC', 'pH']\n",
    "        \n",
    "    def __init__(self, dataset_name, cv=False):\n",
    "        trains, tests     = self.load_files(dataset_name)\n",
    "        self.cv           = cv\n",
    "        self.dataset_name = dataset_name\n",
    "        \n",
    "        if cv:\n",
    "            \n",
    "            params = {\n",
    "            'test_size': 0.2,\n",
    "            'random_state': 3\n",
    "            }\n",
    "\n",
    "            self.itrain,  self.itest  = cross_validation.split_dataset(len(trains[0]), **params)\n",
    "            self.ytrains, self.ytests = utils.get_Ys(y_Ca, y_P, y_Sand, y_SOC, y_pH, itrain, itest)\n",
    "    \n",
    "    def load_files(self, dataset_name):\n",
    "        self.trains, self.tests = utils.load_datasets(dataset_name, self.labels)\n",
    "        return self.trains, self.tests\n",
    "    \n",
    "    def predict(self):\n",
    "        self.preds = defaultdict(list)\n",
    "        \n",
    "        for i in range(len(self.labels)):\n",
    "            if self.cv:\n",
    "                self.Xtr, self.Xte  = utils.get_Xs(self.trains[i], self.itrain, self.itest)\n",
    "            else:\n",
    "                self.Xte = self.tests[i]\n",
    "                \n",
    "            model_names = os.listdir(path=os.path.join(basepath, 'data/processed/%s/%s/models'%(self.dataset_name, self.labels[i])))\n",
    "            for j in range(len(model_names)):\n",
    "                model = joblib.load(os.path.join(basepath, 'data/processed/%s/%s/models/%s/%s'%(self.dataset_name, self.labels[i], model_names[j], model_names[j])))\n",
    "                self.preds[self.labels[i]].append(model.predict(self.Xte))  \n",
    "\n",
    "        return self.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg1    = Averaging('dataset_5', cv=False)\n",
    "preds1  = avg1.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg2    = Averaging('dataset_6', cv=False)\n",
    "preds2  = avg2.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_preds = defaultdict(list)\n",
    "\n",
    "for k, v in preds1.items():\n",
    "    for p in v:\n",
    "        final_preds[k].append(p)\n",
    "    \n",
    "for k, v in preds2.items():\n",
    "    for p in v:\n",
    "        final_preds[k].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_all_targets = [final_preds['Ca'],\n",
    "                           final_preds['P'],\n",
    "                           final_preds['Sand'],\n",
    "                           final_preds['SOC'],\n",
    "                           final_preds['pH']\n",
    "                          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE for index:1 is: 0.482645\n",
      "MCRMSE for index:2 is: 0.733739\n",
      "MCRMSE for index:3 is: 0.392174\n",
      "MCRMSE for index:4 is: 0.415246\n",
      "MCRMSE for index:5 is: 0.526342\n",
      "\n",
      "=================================\n",
      "MCRMSE for all of the targets:  0.510029181453\n"
     ]
    }
   ],
   "source": [
    "balanced_preds = []\n",
    "weights = []\n",
    "\n",
    "for i in range(5):\n",
    "    weight, balanced_pred = find_weights.find(avg1.ytests[i], predictions_all_targets[i])\n",
    "    \n",
    "    weights.append(weight)\n",
    "    print('MCRMSE for index:%d is: %f'%(i+1, eval_metric.mcrmse([avg1.ytests[i]], [balanced_pred])))\n",
    "    balanced_preds.append(balanced_pred)\n",
    "\n",
    "# print(len(balanced_preds[0]))\n",
    "print('\\n=================================')\n",
    "print('MCRMSE for all of the targets: ', eval_metric.mcrmse(y_tests, balanced_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/interim/weights/weights',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/interim/weights/weights_01.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/interim/weights/weights_02.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/interim/weights/weights_03.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/interim/weights/weights_04.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/interim/weights/weights_05.npy']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(weights, os.path.join(basepath, 'data/interim/weights/weights'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = joblib.load(os.path.join(basepath, 'data/interim/weights/weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_Ca_stacked   = find_weights.stack_predictions(final_preds['Ca'])\n",
    "predictions_P_stacked    = find_weights.stack_predictions(final_preds['P'])\n",
    "predictions_Sand_stacked = find_weights.stack_predictions(final_preds['Sand'])\n",
    "predictions_SOC_stacked  = find_weights.stack_predictions(final_preds['SOC'])\n",
    "predictions_pH_stacked   = find_weights.stack_predictions(final_preds['pH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_preds_Ca   = find_weights.balance_predictions(y_Ca, predictions_Ca_stacked, weights[0])\n",
    "final_preds_P    = find_weights.balance_predictions(y_Ca, predictions_P_stacked, weights[1])\n",
    "final_preds_Sand = find_weights.balance_predictions(y_Ca, predictions_Sand_stacked, weights[2])\n",
    "final_preds_SOC  = find_weights.balance_predictions(y_Ca, predictions_SOC_stacked, weights[3])\n",
    "final_preds_pH   = find_weights.balance_predictions(y_Ca, predictions_pH_stacked, weights[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub['Ca']   = final_preds_Ca\n",
    "sample_sub['P']    = final_preds_P\n",
    "sample_sub['Sand'] = final_preds_Sand\n",
    "sample_sub['SOC']  = final_preds_SOC\n",
    "sample_sub['pH']   = final_preds_pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub.to_csv(os.path.join(basepath, 'submissions/2_datasets_clustered.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
