{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/African_Soil_Property_Prediction/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files\n",
    "\n",
    "train = pd.read_csv(os.path.join(basepath, 'data/raw/training.csv'))\n",
    "test = pd.read_csv(os.path.join(basepath, 'data/raw/sorted_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Absorbance levels at different wavelength. **\n",
    "\n",
    "- Include all of the features involving absorbance levels at different wavelengths.\n",
    "- We can choose to include C02 band if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MIR:\n",
    "    def __init__(self, train, test, CO2_band=False):\n",
    "        self.train     = train\n",
    "        self.test      = test\n",
    "        self.CO2_band  = CO2_band\n",
    "    \n",
    "    def prepare(self):\n",
    "        # initiates the process\n",
    "        self.extract_absorbance_levels()\n",
    "        \n",
    "    def extract_absorbance_levels(self):\n",
    "        \n",
    "        # there are 3578 mid-infrared absorbance features\n",
    "        features = self.train.columns[1:3579] # start from 1 because we won't include PIDN\n",
    "        \n",
    "        if not self.CO2_band:\n",
    "            self.train_ = self.train[features]\n",
    "            self.test_  = self.test[features]\n",
    "        else:\n",
    "            # remove the CO2 band from the dataset\n",
    "            start_index = list(features).index('m2379.76')\n",
    "            end_index   = list(features).index('m2352.76')\n",
    "            \n",
    "            co2_features    = features[start_index:end_index+1]\n",
    "            features_wo_co2 = features.drop(co2_features)\n",
    "            \n",
    "            self.train_  = self.train[features_wo_co2]\n",
    "            self.test_   = self.test[features_wo_co2]\n",
    "            \n",
    "    def get_dataset(self):\n",
    "        \n",
    "        # return the prepared datasets\n",
    "        return self.train_, self.test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_1/test/test',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_1/test/test_01.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_1/test/test_02.npy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = MIR(train, test)\n",
    "d1.prepare()\n",
    "\n",
    "train_1, test_1 = d1.get_dataset()\n",
    "\n",
    "# dump the dataset onto the disk\n",
    "joblib.dump(train_1, os.path.join(basepath, 'data/processed/dataset_1/train/train'))\n",
    "joblib.dump(test_1, os.path.join(basepath, 'data/processed/dataset_1/test/test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_2/test/test',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_2/test/test_01.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_2/test/test_02.npy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = MIR(train, test, CO2_band=True)\n",
    "d2.prepare()\n",
    "\n",
    "train_2, test_2 = d2.get_dataset()\n",
    "\n",
    "# dump the dataset onto the disk\n",
    "joblib.dump(train_2, os.path.join(basepath, 'data/processed/dataset_2/train/train'))\n",
    "joblib.dump(test_2, os.path.join(basepath, 'data/processed/dataset_2/test/test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Spatial Data. **\n",
    "\n",
    "* Spatial predictors from remote sensing data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Spatial:\n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test  = test\n",
    "    \n",
    "    def prepare(self):\n",
    "        self.extract_spatial_features()\n",
    "    \n",
    "    def extract_spatial_features(self):\n",
    "        features = self.train.columns\n",
    "        \n",
    "        spatial_features = features[-21:-6]\n",
    "        \n",
    "        self.train_ = self.train[spatial_features]\n",
    "        self.test_  = self.test[spatial_features]\n",
    "        \n",
    "    def get_dataset(self):\n",
    "        return self.train_, self.test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_3/test/test',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_3/test/test_01.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_3/test/test_02.npy']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = Spatial(train, test)\n",
    "d3.prepare()\n",
    "\n",
    "train_3, test_3 = d3.get_dataset()\n",
    "\n",
    "joblib.dump(train_3, os.path.join(basepath, 'data/processed/dataset_3/train/train'))\n",
    "joblib.dump(test_3, os.path.join(basepath, 'data/processed/dataset_3/test/test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Take the first order derivative of the features. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Derivative:\n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "    \n",
    "    def prepare(self):\n",
    "        self.take_derivative()\n",
    "    \n",
    "    def get_absorbance_features(self):\n",
    "        features = self.train.columns\n",
    "        \n",
    "        return features[1:3579]\n",
    "    \n",
    "    def take_derivative(self):\n",
    "        absorbance_features = self.get_absorbance_features()\n",
    "        \n",
    "        self.train_ = self.train[absorbance_features].diff(periods=-1, axis=1).dropna(axis=1)\n",
    "        self.test_  = self.test[absorbance_features].diff(periods=-1, axis=1).dropna(axis=1)\n",
    "        \n",
    "    def get_dataset(self):\n",
    "        return self.train_, self.test_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_4/test/test',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_4/test/test_01.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/dataset_4/test/test_02.npy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4 = Derivative(train, test)\n",
    "d4.prepare()\n",
    "\n",
    "train_4, test_4 = d4.get_dataset()\n",
    "\n",
    "joblib.dump(train_4, os.path.join(basepath, 'data/processed/dataset_4/train/train'))\n",
    "joblib.dump(test_4, os.path.join(basepath, 'data/processed/dataset_4/test/test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** All of the above datasets assume that all the features are required for each of the target variable. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prepare dataset after feature selection. **\n",
    "\n",
    "* Transform all of the features and group them into bins of 8.\n",
    "* Apply average of the values.\n",
    "* Calculate pearson score with the target variable.\n",
    "* Store feature relevance dataframe instead of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureRelevance:\n",
    "    def __init__(self, train):\n",
    "        self.train = train\n",
    "        \n",
    "    def get_absorbance_features(self):\n",
    "        features = self.train.columns\n",
    "        \n",
    "        return features[1:-5]\n",
    "        \n",
    "    def prepare(self):\n",
    "        absorbance_features = self.get_absorbance_features()\n",
    "        \n",
    "        self.train_ = self.train[absorbance_features]\n",
    "        self.train_['Depth'] = (self.train_.Depth == 'TopSoil').astype(np.int)\n",
    "        \n",
    "        \n",
    "        feature_relevance_Ca   = self.feature_relevance(self.train_, self.train.Ca)\n",
    "        feature_relevance_P    = self.feature_relevance(self.train_, self.train.P)\n",
    "        feature_relevance_Sand = self.feature_relevance(self.train_, self.train.Sand)\n",
    "        feature_relevance_SOC  = self.feature_relevance(self.train_, self.train.SOC)\n",
    "        feature_relevance_pH   = self.feature_relevance(self.train_, self.train.pH)\n",
    "        \n",
    "        feature_rel_df = pd.DataFrame({'variables': self.train_.columns, \n",
    "                               'Ca_r_squared': feature_relevance_Ca,\n",
    "                               'P_r_squared': feature_relevance_P,\n",
    "                               'Sand_r_squared': feature_relevance_Sand,\n",
    "                               'SOC_r_squared': feature_relevance_SOC,\n",
    "                               'pH_r_squared': feature_relevance_pH\n",
    "                              })\n",
    "        \n",
    "        return feature_rel_df\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_r_squared(X, y):\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(X, y)\n",
    "        return r_value ** 2\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_score(X, y, bins):\n",
    "        X_agg = []\n",
    "        y_agg = []\n",
    "\n",
    "        for bin_ in range(bins.nunique()):\n",
    "            mask = (bins == bin_)\n",
    "\n",
    "            X_agg.append(X.loc[mask].mean())\n",
    "            y_agg.append(y.loc[mask].mean())\n",
    "\n",
    "        X_agg = np.array(X_agg)\n",
    "        y_agg = np.array(y_agg)\n",
    "\n",
    "        r_squared = FeatureRelevance.calculate_r_squared(X_agg, y_agg)\n",
    "\n",
    "        return r_squared\n",
    "    \n",
    "    @staticmethod\n",
    "    def feature_r_squared(X, y, features, bins):\n",
    "        return [FeatureRelevance.calculate_score(X[feature], y, bins) for feature in features]\n",
    "\n",
    "    @staticmethod\n",
    "    def feature_relevance(X, y, nbins=8):\n",
    "\n",
    "        features = X.columns\n",
    "        bins = pd.cut(X[features[0]], nbins, labels=False)\n",
    "\n",
    "        return FeatureRelevance.feature_r_squared(X, y, features, bins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = FeatureRelevance(train)\n",
    "feature_rel_df = f.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/interim/feature_relevance/feat_rel_df',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/interim/feature_relevance/feat_rel_df_01.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/interim/feature_relevance/feat_rel_df_02.npy']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the feature relevance dataframe onto disk\n",
    "joblib.dump(feature_rel_df, os.path.join(basepath, 'data/interim/feature_relevance/feat_rel_df'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Prepare a dataset from feature relevance dataframe. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load feature relevance dataframe from the disk\n",
    "feature_rel_df = joblib.load(os.path.join(basepath, 'data/interim/feature_relevance/feat_rel_df'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Relevant_Features:\n",
    "    \n",
    "    def __init__(self, train, test):\n",
    "        self.train  = train\n",
    "        self.test   = test\n",
    "        self.labels = ['Ca', 'P', 'Sand', 'SOC', 'pH']\n",
    "     \n",
    "    def prepare(self, feature_rel_df, n_features=1000):\n",
    "        self.get_relevant_features(feature_rel_df, n_features)\n",
    "        self.save_featureset_per_target()\n",
    "        \n",
    "    def get_relevant_features(self, rel_df, n_features):\n",
    "        n_labels = len(self.labels)\n",
    "        relevant_features = []\n",
    "\n",
    "        for i in range(n_labels):\n",
    "            features = rel_df.sort_values(by='%s_r_squared'%(self.labels[i]), ascending=False)['variables'][:n_features]\n",
    "            relevant_features.append(features)\n",
    "\n",
    "        self.relevant_features = relevant_features\n",
    "        return relevant_features\n",
    "    \n",
    "    def save_featureset_per_target(self):\n",
    "        for i in range(len(self.labels)):\n",
    "            train_, test_ = self.train[self.relevant_features[i]], self.test[self.relevant_features[i]]\n",
    "            \n",
    "            joblib.dump(train_, os.path.join(basepath, 'data/processed/dataset_5/%s/train/train'%self.labels[i]))\n",
    "            joblib.dump(test_, os.path.join(basepath, 'data/processed/dataset_5/%s/test/test'%self.labels[i]))\n",
    "            \n",
    "            print('Dumped datasets for label: %s'%(self.labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped datasets for label: Ca\n",
      "Dumped datasets for label: P\n",
      "Dumped datasets for label: Sand\n",
      "Dumped datasets for label: SOC\n",
      "Dumped datasets for label: pH\n"
     ]
    }
   ],
   "source": [
    "d5 = Relevant_Features(train, test)\n",
    "d5.prepare(feature_rel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
