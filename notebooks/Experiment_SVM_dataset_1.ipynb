{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Objective **\n",
    "\n",
    "* Learn how to structure the experiments ?\n",
    "* Hyper-parameter tuning for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy.optimize import nnls\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/African_Soil_Property_Prediction/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from models import cross_validation, eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files\n",
    "train = pd.read_csv(os.path.join(basepath, 'data/raw/training.csv'))\n",
    "test = pd.read_csv(os.path.join(basepath, 'data/raw/sorted_test.csv'))\n",
    "sample_sub = pd.read_csv(os.path.join(basepath, 'data/raw/sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load a dataset\n",
    "\n",
    "train_1    = joblib.load(os.path.join(basepath, 'data/processed/dataset_1/train')) # MIR features\n",
    "test_1     = joblib.load(os.path.join(basepath, 'data/processed/dataset_1/test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define target variables\n",
    "\n",
    "y_Ca    = train.Ca\n",
    "y_P     = train.P\n",
    "y_Sand  = train.Sand\n",
    "y_SOC   = train.SOC\n",
    "y_pH    = train.pH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split datasets into training and test set. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size' : 0.2,\n",
    "    'random_state' : 4\n",
    "}\n",
    "\n",
    "itrain, itest = cross_validation.split_dataset(len(train_1), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_Xs(X, itrain, itest):\n",
    "    X_train = X.iloc[itrain]\n",
    "    X_test  = X.iloc[itest]\n",
    "    \n",
    "    return X_train, X_test\n",
    "    \n",
    "def get_Ys(y_Ca, y_P, y_Sand, y_SOC, y_pH, itrain, itest):\n",
    "    y_train_Ca = y_Ca.iloc[itrain]\n",
    "    y_test_Ca  = y_Ca.iloc[itest]\n",
    "    \n",
    "    y_train_P  = y_P.iloc[itrain]\n",
    "    y_test_P  = y_P.iloc[itest]\n",
    "    \n",
    "    y_train_Sand  = y_Sand.iloc[itrain]\n",
    "    y_test_Sand  = y_Sand.iloc[itest]\n",
    "    \n",
    "    y_train_SOC  = y_SOC.iloc[itrain]\n",
    "    y_test_SOC  = y_SOC.iloc[itest]\n",
    "    \n",
    "    y_train_pH  = y_pH.iloc[itrain]\n",
    "    y_test_pH  = y_pH.iloc[itest]\n",
    "    \n",
    "    \n",
    "    return ([y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH],\n",
    "            [y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH])\n",
    "\n",
    "X_train_1, X_test_1    = get_Xs(train_1, itrain, itest)\n",
    "\n",
    "y_trains, y_tests = get_Ys(y_Ca, y_P, y_Sand, y_SOC, y_pH, itrain, itest)\n",
    "\n",
    "y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH = y_trains\n",
    "y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH = y_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** List of Models. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instantiate_models(targets, **params):\n",
    "    pipelines = []\n",
    "    \n",
    "    for i in range(len(targets)):\n",
    "        # based on the target variable create a pipeline\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "                ('pca', RandomizedPCA(n_components=params['n_components'], whiten=True, random_state=11)),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', SVR(kernel=params['kernel']))\n",
    "            ])\n",
    "        \n",
    "        pipelines.append(pipeline)\n",
    "    \n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_components': 100,\n",
    "    'kernel': 'rbf'\n",
    "}\n",
    "\n",
    "pipelines = instantiate_models(['Ca', 'P', 'Sand', 'SOC', 'pH'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_components': 100,\n",
    "    'kernel': 'linear'\n",
    "}\n",
    "\n",
    "pipelines_linear = instantiate_models(['Ca', 'P', 'Sand', 'SOC', 'pH'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_components': 100,\n",
    "    'kernel': 'poly'\n",
    "}\n",
    "\n",
    "pipelines_poly = instantiate_models(['Ca', 'P', 'Sand', 'SOC', 'pH'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up local cross validation scheme\n",
    "\n",
    "pipelines = [Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('pca', RandomizedPCA(n_components=100, whiten=True, random_state=11)),\n",
    "                ('model', SVR(kernel='linear'))\n",
    "            ])\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Ca\n",
      "\n",
      "======== Iteration: 0\n",
      "\n",
      "MCRMSE score: 0.159422\n",
      "\n",
      "======== Iteration: 1\n",
      "\n",
      "MCRMSE score: 0.318131\n",
      "\n",
      "======== Iteration: 2\n",
      "\n",
      "MCRMSE score: 0.498546\n",
      "\n",
      "======== Iteration: 3\n",
      "\n",
      "MCRMSE score: 0.492167\n",
      "\n",
      "======== Iteration: 4\n",
      "\n",
      "MCRMSE score: 0.617636\n",
      "\n",
      "======== Iteration: 5\n",
      "\n",
      "MCRMSE score: 0.391185\n",
      "\n",
      "======== Iteration: 6\n",
      "\n",
      "MCRMSE score: 0.172568\n",
      "\n",
      "======== Iteration: 7\n",
      "\n",
      "MCRMSE score: 0.267217\n",
      "\n",
      "======== Iteration: 8\n",
      "\n",
      "MCRMSE score: 0.328175\n",
      "\n",
      "======== Iteration: 9\n",
      "\n",
      "MCRMSE score: 0.408929\n",
      "\n",
      "=============================\n",
      "Mean CV score: 0.365398\n"
     ]
    }
   ],
   "source": [
    "print('Target: Ca\\n')\n",
    "cv_score = cross_validation.cv_scheme(pipelines, [X_train_1], [y_train_Ca])\n",
    "print('=============================')\n",
    "print('Mean CV score: %f'%cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipelines = [Pipeline([\n",
    "                ('scaler', MinMaxScaler()),\n",
    "                ('pca', PCA(n_components=100, whiten=True)),\n",
    "                ('model', SVR(C=10., kernel='linear'))\n",
    "            ])\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: P\n",
      "\n",
      "======== Iteration: 0\n",
      "\n",
      "MCRMSE score: 1.507841\n",
      "\n",
      "======== Iteration: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Target: P\\n')\n",
    "cv_score = cross_validation.cv_scheme(pipelines, [X_train_1], [y_train_P])\n",
    "print('=============================')\n",
    "print('Mean CV score: %f'%cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelines = [Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('pca', RandomizedPCA(n_components=100, whiten=True, random_state=11)),\n",
    "                ('model', SVR(kernel='linear'))\n",
    "            ])\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Sand\n",
      "\n",
      "======== Iteration: 0\n",
      "\n",
      "MCRMSE score: 0.354989\n",
      "\n",
      "======== Iteration: 1\n",
      "\n",
      "MCRMSE score: 0.319652\n",
      "\n",
      "======== Iteration: 2\n",
      "\n",
      "MCRMSE score: 0.470740\n",
      "\n",
      "======== Iteration: 3\n",
      "\n",
      "MCRMSE score: 0.427449\n",
      "\n",
      "======== Iteration: 4\n",
      "\n",
      "MCRMSE score: 0.455251\n",
      "\n",
      "======== Iteration: 5\n",
      "\n",
      "MCRMSE score: 0.415363\n",
      "\n",
      "======== Iteration: 6\n",
      "\n",
      "MCRMSE score: 0.362000\n",
      "\n",
      "======== Iteration: 7\n",
      "\n",
      "MCRMSE score: 0.342332\n",
      "\n",
      "======== Iteration: 8\n",
      "\n",
      "MCRMSE score: 0.406449\n",
      "\n",
      "======== Iteration: 9\n",
      "\n",
      "MCRMSE score: 0.350251\n",
      "\n",
      "=============================\n",
      "Mean CV score: 0.390447\n"
     ]
    }
   ],
   "source": [
    "print('Target: Sand\\n')\n",
    "cv_score = cross_validation.cv_scheme(pipelines, [X_train_1], [y_train_Sand])\n",
    "print('=============================')\n",
    "print('Mean CV score: %f'%cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: SOC\n",
      "\n",
      "======== Iteration: 0\n",
      "\n",
      "MCRMSE score: 0.415484\n",
      "\n",
      "======== Iteration: 1\n",
      "\n",
      "MCRMSE score: 0.224141\n",
      "\n",
      "======== Iteration: 2\n",
      "\n",
      "MCRMSE score: 0.295390\n",
      "\n",
      "======== Iteration: 3\n",
      "\n",
      "MCRMSE score: 0.297568\n",
      "\n",
      "======== Iteration: 4\n",
      "\n",
      "MCRMSE score: 0.414757\n",
      "\n",
      "======== Iteration: 5\n",
      "\n",
      "MCRMSE score: 0.398907\n",
      "\n",
      "======== Iteration: 6\n",
      "\n",
      "MCRMSE score: 0.323590\n",
      "\n",
      "======== Iteration: 7\n",
      "\n",
      "MCRMSE score: 0.304843\n",
      "\n",
      "======== Iteration: 8\n",
      "\n",
      "MCRMSE score: 0.609300\n",
      "\n",
      "======== Iteration: 9\n",
      "\n",
      "MCRMSE score: 0.328634\n",
      "\n",
      "=============================\n",
      "Mean CV score: 0.361261\n"
     ]
    }
   ],
   "source": [
    "print('Target: SOC\\n')\n",
    "cv_score = cross_validation.cv_scheme(pipelines, [X_train_1], [y_train_SOC])\n",
    "print('=============================')\n",
    "print('Mean CV score: %f'%cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelines = [Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('pca', RandomizedPCA(n_components=100, whiten=True, random_state=11)),\n",
    "                ('model', SVR(kernel='linear'))\n",
    "            ])\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: pH\n",
      "\n",
      "======== Iteration: 0\n",
      "\n",
      "MCRMSE score: 0.335811\n",
      "\n",
      "======== Iteration: 1\n",
      "\n",
      "MCRMSE score: 0.316056\n",
      "\n",
      "======== Iteration: 2\n",
      "\n",
      "MCRMSE score: 0.393786\n",
      "\n",
      "======== Iteration: 3\n",
      "\n",
      "MCRMSE score: 0.392708\n",
      "\n",
      "======== Iteration: 4\n",
      "\n",
      "MCRMSE score: 0.445078\n",
      "\n",
      "======== Iteration: 5\n",
      "\n",
      "MCRMSE score: 0.371086\n",
      "\n",
      "======== Iteration: 6\n",
      "\n",
      "MCRMSE score: 0.399387\n",
      "\n",
      "======== Iteration: 7\n",
      "\n",
      "MCRMSE score: 0.366781\n",
      "\n",
      "======== Iteration: 8\n",
      "\n",
      "MCRMSE score: 0.394995\n",
      "\n",
      "======== Iteration: 9\n",
      "\n",
      "MCRMSE score: 0.467595\n",
      "\n",
      "=============================\n",
      "Mean CV score: 0.388328\n"
     ]
    }
   ],
   "source": [
    "print('Target: pH\\n')\n",
    "cv_score = cross_validation.cv_scheme(pipelines, [X_train_1], [y_train_pH])\n",
    "print('=============================')\n",
    "print('Mean CV score: %f'%cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(pipeline, X, y):\n",
    "    \"\"\"\n",
    "    Takes in a pipeline and corresponding X and y\n",
    "    and trains a model\n",
    "    \"\"\"\n",
    "    return pipeline.fit(X, y)\n",
    "\n",
    "def train_pipelines(pipelines, Xs, ys):\n",
    "    for i in range(len(pipelines)):\n",
    "        pipelines[i] = train_model(pipelines[i], Xs[i], ys[i])\n",
    "        \n",
    "    return pipelines\n",
    "\n",
    "def predictions(pipelines, Xtest):\n",
    "    return np.array([pipelines[i].predict(Xtest[i]) for i in range(len(pipelines))])\n",
    "                               \n",
    "pipelines_trained = train_pipelines(pipelines, [X_train_1, X_train_1, X_train_1, X_train_1, X_train_1],\n",
    "                                    [y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH])\n",
    "\n",
    "pipelines_predictions = predictions(pipelines_trained, [X_test_1, X_test_1, X_test_1, X_test_1, X_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlate_predictions(y_1, y_2, labels):\n",
    "    \"\"\"\n",
    "    y_1 : Dataframe representing predictions for all of the target variables\n",
    "    y_2 : Dataframe representing predictions for all of the target variables\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        print('For %s correlation coefficient is: %f'%(labels[i], pearsonr(y_1[i], y_2[i])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelines_linear_trained = train_pipelines(pipelines_linear, [X_train_1, X_train_1, X_train_1, X_train_1, X_train_1],\n",
    "                                    [y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH])\n",
    "\n",
    "pipelines_linear_predictions = predictions(pipelines_linear_trained, [X_test_1, X_test_1, X_test_1, X_test_1, X_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelines_poly_trained = train_pipelines(pipelines_poly, [X_train_1, X_train_1, X_train_1, X_train_1, X_train_1],\n",
    "                                    [y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH])\n",
    "\n",
    "pipelines_poly_predictions = predictions(pipelines_poly_trained, [X_test_1, X_test_1, X_test_1, X_test_1, X_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ca correlation coefficient is: 0.752028\n",
      "For P correlation coefficient is: 0.746886\n",
      "For Sand correlation coefficient is: 0.951844\n",
      "For SOC correlation coefficient is: 0.874771\n",
      "For pH correlation coefficient is: 0.887052\n"
     ]
    }
   ],
   "source": [
    "correlate_predictions(pipelines_predictions, pipelines_linear_predictions, ['Ca', 'P', 'Sand', 'SOC', 'pH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ca correlation coefficient is: 0.675932\n",
      "For P correlation coefficient is: 0.821524\n",
      "For Sand correlation coefficient is: 0.841555\n",
      "For SOC correlation coefficient is: 0.801434\n",
      "For pH correlation coefficient is: 0.753194\n"
     ]
    }
   ],
   "source": [
    "correlate_predictions(pipelines_predictions, pipelines_poly_predictions, ['Ca', 'P', 'Sand', 'SOC', 'pH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ca correlation coefficient is: 0.881251\n",
      "For P correlation coefficient is: 0.600292\n",
      "For Sand correlation coefficient is: 0.837486\n",
      "For SOC correlation coefficient is: 0.889768\n",
      "For pH correlation coefficient is: 0.843601\n"
     ]
    }
   ],
   "source": [
    "correlate_predictions(pipelines_linear_predictions, pipelines_poly_predictions, ['Ca', 'P', 'Sand', 'SOC', 'pH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_selected(data, labels):\n",
    "    weights, _ = nnls(data[:len(labels)], labels)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_Ca = np.vstack([y_dataset_1_Ca, y_dataset_2_Ca, y_dataset_3_Ca]).T\n",
    "preds_P = np.vstack([y_dataset_1_P, y_dataset_2_P, y_dataset_3_P]).T\n",
    "preds_Sand = np.vstack([y_dataset_1_Sand, y_dataset_2_Sand, y_dataset_3_Sand]).T\n",
    "preds_SOC = np.vstack([y_dataset_1_SOC, y_dataset_2_SOC, y_dataset_3_SOC]).T\n",
    "preds_pH = np.vstack([y_dataset_1_pH, y_dataset_2_pH, y_dataset_3_pH]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_Ca = weight_selected(preds_Ca, y_test_Ca)\n",
    "weights_P = weight_selected(preds_P, y_test_P)\n",
    "weights_Sand = weight_selected(preds_Sand, y_test_Sand)\n",
    "weights_SOC = weight_selected(preds_SOC, y_test_SOC)\n",
    "weights_pH = weight_selected(preds_pH, y_test_pH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "balanced_pred_Ca = preds_Ca[:, weights_Ca > 0].mean(axis=1)[:len(y_test_Ca)]\n",
    "balanced_pred_P = preds_P[:, weights_P > 0].mean(axis=1)[:len(y_test_P)]\n",
    "balanced_pred_Sand = preds_Sand[:, weights_Sand > 0].mean(axis=1)[:len(y_test_Sand)]\n",
    "balanced_pred_SOC = preds_SOC[:, weights_SOC > 0].mean(axis=1)[:len(y_test_SOC)]\n",
    "balanced_pred_pH = preds_pH[:, weights_pH > 0].mean(axis=1)[:len(y_test_pH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE after balancing: 0.412842\n"
     ]
    }
   ],
   "source": [
    "print('MCRMSE after balancing: %f' %(eval_metric.mcrmse([y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH],\n",
    "                                                 [balanced_pred_Ca, balanced_pred_P, balanced_pred_Sand, balanced_pred_SOC,\n",
    "                                                  balanced_pred_pH])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training on full dataset. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_1.fit(train_1, y_Ca)\n",
    "pipeline_2.fit(train_1, y_P)\n",
    "pipeline_3.fit(train_1, y_Sand)\n",
    "pipeline_4.fit(train_1, y_SOC)\n",
    "pipeline_5.fit(train_1, y_pH)\n",
    "\n",
    "pipeline_6.fit(train_2, y_Ca)\n",
    "pipeline_7.fit(train_2, y_P)\n",
    "pipeline_8.fit(train_2, y_Sand)\n",
    "pipeline_9.fit(train_2, y_SOC)\n",
    "pipeline_10.fit(train_2, y_pH)\n",
    "\n",
    "pipeline_11.fit(train_3, y_Ca)\n",
    "pipeline_12.fit(train_3, y_P)\n",
    "pipeline_13.fit(train_3, y_Sand)\n",
    "pipeline_14.fit(train_3, y_SOC)\n",
    "pipeline_15.fit(train_3, y_pH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH_01.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH_02.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH_03.npy',\n",
       " '/home/abhishek/Desktop/src/African_Soil_Property_Prediction/data/processed/pipeline_full_pH/dataset_3/model/pH_04.npy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline_1, os.path.join(basepath, 'data/processed/pipeline_full_Ca/dataset_1/model/Ca'))\n",
    "joblib.dump(pipeline_2, os.path.join(basepath, 'data/processed/pipeline_full_P/dataset_1/model/P'))\n",
    "joblib.dump(pipeline_3, os.path.join(basepath, 'data/processed/pipeline_full_Sand/dataset_1/model/Sand'))\n",
    "joblib.dump(pipeline_4, os.path.join(basepath, 'data/processed/pipeline_full_SOC/dataset_1/model/SOC'))\n",
    "joblib.dump(pipeline_5, os.path.join(basepath, 'data/processed/pipeline_full_pH/dataset_1/model/pH'))\n",
    "\n",
    "joblib.dump(pipeline_6, os.path.join(basepath, 'data/processed/pipeline_full_Ca/dataset_2/model/Ca'))\n",
    "joblib.dump(pipeline_7, os.path.join(basepath, 'data/processed/pipeline_full_P/dataset_2/model/P'))\n",
    "joblib.dump(pipeline_8, os.path.join(basepath, 'data/processed/pipeline_full_Sand/dataset_2/model/Sand'))\n",
    "joblib.dump(pipeline_9, os.path.join(basepath, 'data/processed/pipeline_full_SOC/dataset_2/model/SOC'))\n",
    "joblib.dump(pipeline_10, os.path.join(basepath, 'data/processed/pipeline_full_pH/dataset_2/model/pH'))\n",
    "\n",
    "joblib.dump(pipeline_11, os.path.join(basepath, 'data/processed/pipeline_full_Ca/dataset_3/model/Ca'))\n",
    "joblib.dump(pipeline_12, os.path.join(basepath, 'data/processed/pipeline_full_P/dataset_3/model/P'))\n",
    "joblib.dump(pipeline_13, os.path.join(basepath, 'data/processed/pipeline_full_Sand/dataset_3/model/Sand'))\n",
    "joblib.dump(pipeline_14, os.path.join(basepath, 'data/processed/pipeline_full_SOC/dataset_3/model/SOC'))\n",
    "joblib.dump(pipeline_15, os.path.join(basepath, 'data/processed/pipeline_full_pH/dataset_3/model/pH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dataset_1_Ca    = pipeline_1.predict(test_1)\n",
    "y_dataset_1_P     = pipeline_2.predict(test_1)\n",
    "y_dataset_1_Sand  = pipeline_3.predict(test_1)\n",
    "y_dataset_1_SOC   = pipeline_4.predict(test_1)\n",
    "y_dataset_1_pH    = pipeline_5.predict(test_1)\n",
    "\n",
    "y_dataset_2_Ca    = pipeline_6.predict(test_2)\n",
    "y_dataset_2_P     = pipeline_7.predict(test_2)\n",
    "y_dataset_2_Sand  = pipeline_8.predict(test_2)\n",
    "y_dataset_2_SOC   = pipeline_9.predict(test_2)\n",
    "y_dataset_2_pH    = pipeline_10.predict(test_2)\n",
    "\n",
    "y_dataset_3_Ca    = pipeline_11.predict(test_3)\n",
    "y_dataset_3_P     = pipeline_12.predict(test_3)\n",
    "y_dataset_3_Sand  = pipeline_13.predict(test_3)\n",
    "y_dataset_3_SOC   = pipeline_14.predict(test_3)\n",
    "y_dataset_3_pH    = pipeline_15.predict(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_Ca = np.vstack([y_dataset_1_Ca, y_dataset_2_Ca, y_dataset_3_Ca]).T\n",
    "preds_P = np.vstack([y_dataset_1_P, y_dataset_2_P, y_dataset_3_P]).T\n",
    "preds_Sand = np.vstack([y_dataset_1_Sand, y_dataset_2_Sand, y_dataset_3_Sand]).T\n",
    "preds_SOC = np.vstack([y_dataset_1_SOC, y_dataset_2_SOC, y_dataset_3_SOC]).T\n",
    "preds_pH = np.vstack([y_dataset_1_pH, y_dataset_2_pH, y_dataset_3_pH]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_pred_Ca = preds_Ca[:, weights_Ca > 0].mean(axis=1)[:len(y_Ca)]\n",
    "balanced_pred_P = preds_P[:, weights_P > 0].mean(axis=1)[:len(y_P)]\n",
    "balanced_pred_Sand = preds_Sand[:, weights_Sand > 0].mean(axis=1)[:len(y_Sand)]\n",
    "balanced_pred_SOC = preds_SOC[:, weights_SOC > 0].mean(axis=1)[:len(y_SOC)]\n",
    "balanced_pred_pH = preds_pH[:, weights_pH > 0].mean(axis=1)[:len(y_pH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub['Ca']   = balanced_pred_Ca\n",
    "sample_sub['P']    = balanced_pred_P\n",
    "sample_sub['pH']   = balanced_pred_pH\n",
    "sample_sub['SOC']  = balanced_pred_SOC\n",
    "sample_sub['Sand'] = balanced_pred_Sand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Public Leaderboard Score: 0.49149 , Private Leaderboard Score: 0.53293 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub.to_csv(os.path.join(basepath, 'submissions/average_models.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
