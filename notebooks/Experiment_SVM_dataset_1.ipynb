{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Objective **\n",
    "\n",
    "* Learn how to structure the experiments ?\n",
    "* Hyper-parameter tuning for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy.optimize import nnls\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/African_Soil_Property_Prediction/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from models import cross_validation, eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files\n",
    "train = pd.read_csv(os.path.join(basepath, 'data/raw/training.csv'))\n",
    "test = pd.read_csv(os.path.join(basepath, 'data/raw/sorted_test.csv'))\n",
    "sample_sub = pd.read_csv(os.path.join(basepath, 'data/raw/sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load a dataset\n",
    "\n",
    "train_1    = joblib.load(os.path.join(basepath, 'data/processed/dataset_1/train')) # MIR features\n",
    "test_1     = joblib.load(os.path.join(basepath, 'data/processed/dataset_1/test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define target variables\n",
    "\n",
    "y_Ca    = train.Ca\n",
    "y_P     = train.P\n",
    "y_Sand  = train.Sand\n",
    "y_SOC   = train.SOC\n",
    "y_pH    = train.pH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split datasets into training and test set. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size' : 0.2,\n",
    "    'random_state' : 4\n",
    "}\n",
    "\n",
    "itrain, itest = cross_validation.split_dataset(len(train_1), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_Xs(X, itrain, itest):\n",
    "    X_train = X.iloc[itrain]\n",
    "    X_test  = X.iloc[itest]\n",
    "    \n",
    "    return X_train, X_test\n",
    "    \n",
    "def get_Ys(y_Ca, y_P, y_Sand, y_SOC, y_pH, itrain, itest):\n",
    "    y_train_Ca = y_Ca.iloc[itrain]\n",
    "    y_test_Ca  = y_Ca.iloc[itest]\n",
    "    \n",
    "    y_train_P  = y_P.iloc[itrain]\n",
    "    y_test_P  = y_P.iloc[itest]\n",
    "    \n",
    "    y_train_Sand  = y_Sand.iloc[itrain]\n",
    "    y_test_Sand  = y_Sand.iloc[itest]\n",
    "    \n",
    "    y_train_SOC  = y_SOC.iloc[itrain]\n",
    "    y_test_SOC  = y_SOC.iloc[itest]\n",
    "    \n",
    "    y_train_pH  = y_pH.iloc[itrain]\n",
    "    y_test_pH  = y_pH.iloc[itest]\n",
    "    \n",
    "    \n",
    "    return ([y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH],\n",
    "            [y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH])\n",
    "\n",
    "X_train_1, X_test_1    = get_Xs(train_1, itrain, itest)\n",
    "\n",
    "y_trains, y_tests = get_Ys(y_Ca, y_P, y_Sand, y_SOC, y_pH, itrain, itest)\n",
    "\n",
    "y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH = y_trains\n",
    "y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH = y_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** List of Models. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instantiate_models(targets, **params):\n",
    "    pipelines = []\n",
    "    \n",
    "    for i in range(len(targets)):\n",
    "        # based on the target variable create a pipeline\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "                ('pca', RandomizedPCA(n_components=params['n_components'], whiten=True, random_state=11)),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', SVR(kernel=params['kernel']))\n",
    "            ])\n",
    "        \n",
    "        pipelines.append(pipeline)\n",
    "    \n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rbf kernel\n",
    "\n",
    "params = {\n",
    "    'n_components': 100,\n",
    "    'kernel': 'rbf'\n",
    "}\n",
    "\n",
    "pipelines_rbf = instantiate_models(['Ca', 'P', 'Sand', 'SOC', 'pH'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear kernel\n",
    "\n",
    "params = {\n",
    "    'n_components': 100,\n",
    "    'kernel': 'linear'\n",
    "}\n",
    "\n",
    "pipelines_linear = instantiate_models(['Ca', 'P', 'Sand', 'SOC', 'pH'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# polynomial kernel\n",
    "\n",
    "params = {\n",
    "    'n_components': 100,\n",
    "    'kernel': 'poly'\n",
    "}\n",
    "\n",
    "pipelines_poly = instantiate_models(['Ca', 'P', 'Sand', 'SOC', 'pH'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Rbf Kernel\n",
      "Target: Ca\n",
      "\n",
      "======== Iteration: 0\n",
      "\n",
      "MCRMSE score: 0.261146\n",
      "\n",
      "======== Iteration: 1\n",
      "\n",
      "MCRMSE score: 0.771985\n",
      "\n",
      "======== Iteration: 2\n",
      "\n",
      "MCRMSE score: 0.909863\n",
      "\n",
      "======== Iteration: 3\n",
      "\n",
      "MCRMSE score: 1.030925\n",
      "\n",
      "======== Iteration: 4\n",
      "\n",
      "MCRMSE score: 1.068632\n",
      "\n",
      "======== Iteration: 5\n",
      "\n",
      "MCRMSE score: 0.392604\n",
      "\n",
      "======== Iteration: 6\n",
      "\n",
      "MCRMSE score: 0.281089\n",
      "\n",
      "======== Iteration: 7\n",
      "\n",
      "MCRMSE score: 0.536600\n",
      "\n",
      "======== Iteration: 8\n",
      "\n",
      "MCRMSE score: 0.447675\n",
      "\n",
      "======== Iteration: 9\n",
      "\n",
      "MCRMSE score: 0.710902\n",
      "\n",
      "=============================\n",
      "Mean CV score: 0.641142\n"
     ]
    }
   ],
   "source": [
    "print('============ Rbf Kernel')\n",
    "print('Target: Ca\\n')\n",
    "cv_score = cross_validation.cv_scheme([pipelines_rbf[0]], [X_train_1], [y_train_Ca])\n",
    "print('=============================')\n",
    "print('Mean CV score: %f'%cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Linear Kernel\n",
      "Target: Ca\n",
      "\n",
      "======== Iteration: 0\n",
      "\n",
      "MCRMSE score: 0.149296\n",
      "\n",
      "======== Iteration: 1\n",
      "\n",
      "MCRMSE score: 0.296696\n",
      "\n",
      "======== Iteration: 2\n",
      "\n",
      "MCRMSE score: 0.498995\n",
      "\n",
      "======== Iteration: 3\n",
      "\n",
      "MCRMSE score: 0.569838\n",
      "\n",
      "======== Iteration: 4\n",
      "\n",
      "MCRMSE score: 0.497455\n",
      "\n",
      "======== Iteration: 5\n",
      "\n",
      "MCRMSE score: 0.419168\n",
      "\n",
      "======== Iteration: 6\n",
      "\n",
      "MCRMSE score: 0.162333\n",
      "\n",
      "======== Iteration: 7\n",
      "\n",
      "MCRMSE score: 0.291380\n",
      "\n",
      "======== Iteration: 8\n",
      "\n",
      "MCRMSE score: 0.316343\n",
      "\n",
      "======== Iteration: 9\n",
      "\n",
      "MCRMSE score: 0.391761\n",
      "\n",
      "=============================\n",
      "Mean CV score: 0.359327\n"
     ]
    }
   ],
   "source": [
    "print('============ Linear Kernel')\n",
    "print('Target: Ca\\n')\n",
    "cv_score = cross_validation.cv_scheme([pipelines_linear[0]], [X_train_1], [y_train_Ca])\n",
    "print('=============================')\n",
    "print('Mean CV score: %f'%cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Poly Kernel\n",
      "Target: Ca\n",
      "\n",
      "======== Iteration: 0\n",
      "\n",
      "MCRMSE score: 0.408076\n",
      "\n",
      "======== Iteration: 1\n",
      "\n",
      "MCRMSE score: 0.541938\n",
      "\n",
      "======== Iteration: 2\n",
      "\n",
      "MCRMSE score: 0.624262\n",
      "\n",
      "======== Iteration: 3\n",
      "\n",
      "MCRMSE score: 1.534261\n",
      "\n",
      "======== Iteration: 4\n",
      "\n",
      "MCRMSE score: 5.572011\n",
      "\n",
      "======== Iteration: 5\n",
      "\n",
      "MCRMSE score: 0.549818\n",
      "\n",
      "======== Iteration: 6\n",
      "\n",
      "MCRMSE score: 0.415179\n",
      "\n",
      "======== Iteration: 7\n",
      "\n",
      "MCRMSE score: 0.792534\n",
      "\n",
      "======== Iteration: 8\n",
      "\n",
      "MCRMSE score: 0.753022\n",
      "\n",
      "======== Iteration: 9\n",
      "\n",
      "MCRMSE score: 0.377009\n",
      "\n",
      "=============================\n",
      "Mean CV score: 1.156811\n"
     ]
    }
   ],
   "source": [
    "print('============ Poly Kernel')\n",
    "print('Target: Ca\\n')\n",
    "cv_score = cross_validation.cv_scheme([pipelines_poly[0]], [X_train_1], [y_train_Ca])\n",
    "print('=============================')\n",
    "print('Mean CV score: %f'%cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(pipeline, X, y):\n",
    "    \"\"\"\n",
    "    Takes in a pipeline and corresponding X and y\n",
    "    and trains a model\n",
    "    \"\"\"\n",
    "    return pipeline.fit(X, y)\n",
    "\n",
    "def train_pipelines(pipelines, Xs, ys):\n",
    "    for i in range(len(pipelines)):\n",
    "        pipelines[i] = train_model(pipelines[i], Xs[i], ys[i])\n",
    "        \n",
    "    return pipelines\n",
    "\n",
    "def predictions(pipelines, Xtest):\n",
    "    return np.array([pipelines[i].predict(Xtest[i]) for i in range(len(pipelines))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlate_predictions(y_1, y_2, labels):\n",
    "    \"\"\"\n",
    "    y_1 : Dataframe representing predictions for all of the target variables\n",
    "    y_2 : Dataframe representing predictions for all of the target variables\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        print('For %s correlation coefficient is: %f'%(labels[i], pearsonr(y_1[i], y_2[i])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train linear, rbf and poly kernels on the various target variables on dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rbf kernel\n",
    "pipelines_rbf_trained = train_pipelines(pipelines_rbf, [X_train_1, X_train_1, X_train_1, X_train_1, X_train_1],\n",
    "                                    [y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH])\n",
    "\n",
    "pipelines_rbf_predictions = predictions(pipelines_rbf_trained, [X_test_1, X_test_1, X_test_1, X_test_1, X_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear kernel\n",
    "pipelines_linear_trained = train_pipelines(pipelines_linear, [X_train_1, X_train_1, X_train_1, X_train_1, X_train_1],\n",
    "                                    [y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH])\n",
    "\n",
    "pipelines_linear_predictions = predictions(pipelines_linear_trained, [X_test_1, X_test_1, X_test_1, X_test_1, X_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# poly kernel\n",
    "pipelines_poly_trained = train_pipelines(pipelines_poly, [X_train_1, X_train_1, X_train_1, X_train_1, X_train_1],\n",
    "                                    [y_train_Ca, y_train_P, y_train_Sand, y_train_SOC, y_train_pH])\n",
    "\n",
    "pipelines_poly_predictions = predictions(pipelines_poly_trained, [X_test_1, X_test_1, X_test_1, X_test_1, X_test_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** See how correlations among predictions. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ca correlation coefficient is: 0.752028\n",
      "For P correlation coefficient is: 0.746886\n",
      "For Sand correlation coefficient is: 0.951844\n",
      "For SOC correlation coefficient is: 0.874771\n",
      "For pH correlation coefficient is: 0.887052\n"
     ]
    }
   ],
   "source": [
    "correlate_predictions(pipelines_rbf_predictions, pipelines_linear_predictions, ['Ca', 'P', 'Sand', 'SOC', 'pH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ca correlation coefficient is: 0.675932\n",
      "For P correlation coefficient is: 0.821524\n",
      "For Sand correlation coefficient is: 0.841555\n",
      "For SOC correlation coefficient is: 0.801434\n",
      "For pH correlation coefficient is: 0.753194\n"
     ]
    }
   ],
   "source": [
    "correlate_predictions(pipelines_rbf_predictions, pipelines_poly_predictions, ['Ca', 'P', 'Sand', 'SOC', 'pH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ca correlation coefficient is: 0.881251\n",
      "For P correlation coefficient is: 0.600292\n",
      "For Sand correlation coefficient is: 0.837486\n",
      "For SOC correlation coefficient is: 0.889768\n",
      "For pH correlation coefficient is: 0.843601\n"
     ]
    }
   ],
   "source": [
    "correlate_predictions(pipelines_linear_predictions, pipelines_poly_predictions, ['Ca', 'P', 'Sand', 'SOC', 'pH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Performance of individual models on test set. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE: 0.611984\n"
     ]
    }
   ],
   "source": [
    "# rbf kernel\n",
    "print('MCRMSE: %f'%(eval_metric.mcrmse([y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH],\n",
    "                                       pipelines_rbf_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE: 0.424516\n"
     ]
    }
   ],
   "source": [
    "# linear kernel\n",
    "print('MCRMSE: %f'%(eval_metric.mcrmse([y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH],\n",
    "                                       pipelines_linear_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE: 0.628008\n"
     ]
    }
   ],
   "source": [
    "# poly kernel\n",
    "print('MCRMSE: %f'%(eval_metric.mcrmse([y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH],\n",
    "                                       pipelines_poly_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Choose weights. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_selected(data, labels):\n",
    "    weights, _ = nnls(data[:len(labels)], labels)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_Ca   = np.vstack([pipelines_rbf_predictions[0], pipelines_linear_predictions[0], pipelines_poly_predictions[0]]).T\n",
    "preds_P    = np.vstack([pipelines_rbf_predictions[1], pipelines_linear_predictions[1], pipelines_poly_predictions[1]]).T\n",
    "preds_Sand = np.vstack([pipelines_rbf_predictions[2], pipelines_linear_predictions[2], pipelines_poly_predictions[2]]).T\n",
    "preds_SOC  = np.vstack([pipelines_rbf_predictions[3], pipelines_linear_predictions[3], pipelines_poly_predictions[3]]).T\n",
    "preds_pH   = np.vstack([pipelines_rbf_predictions[4], pipelines_linear_predictions[4], pipelines_poly_predictions[4]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_Ca = weight_selected(preds_Ca, y_test_Ca)\n",
    "weights_P = weight_selected(preds_P, y_test_P)\n",
    "weights_Sand = weight_selected(preds_Sand, y_test_Sand)\n",
    "weights_SOC = weight_selected(preds_SOC, y_test_SOC)\n",
    "weights_pH = weight_selected(preds_pH, y_test_pH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "balanced_pred_Ca = preds_Ca[:, weights_Ca > 0].mean(axis=1)[:len(y_test_Ca)]\n",
    "balanced_pred_P = preds_P[:, weights_P > 0].mean(axis=1)[:len(y_test_P)]\n",
    "balanced_pred_Sand = preds_Sand[:, weights_Sand > 0].mean(axis=1)[:len(y_test_Sand)]\n",
    "balanced_pred_SOC = preds_SOC[:, weights_SOC > 0].mean(axis=1)[:len(y_test_SOC)]\n",
    "balanced_pred_pH = preds_pH[:, weights_pH > 0].mean(axis=1)[:len(y_test_pH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE after balancing: 0.468917\n"
     ]
    }
   ],
   "source": [
    "print('MCRMSE after balancing: %f' %(eval_metric.mcrmse([y_test_Ca, y_test_P, y_test_Sand, y_test_SOC, y_test_pH],\n",
    "                                                 [balanced_pred_Ca, balanced_pred_P, balanced_pred_Sand, balanced_pred_SOC,\n",
    "                                                  balanced_pred_pH])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training on full dataset. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rbf kernel\n",
    "pipelines_rbf_trained = train_pipelines(pipelines_rbf, [train_1, train_1, train_1, train_1, train_1],\n",
    "                                    [y_Ca, y_P, y_Sand, y_SOC, y_pH])\n",
    "\n",
    "pipelines_rbf_predictions = predictions(pipelines_rbf_trained, [test_1, test_1, test_1, test_1, test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear kernel\n",
    "pipelines_linear_trained = train_pipelines(pipelines_linear, [train_1, train_1, train_1, train_1, train_1],\n",
    "                                    [y_Ca, y_P, y_Sand, y_SOC, y_pH])\n",
    "\n",
    "pipelines_linear_predictions = predictions(pipelines_linear_trained, [test_1, test_1, test_1, test_1, test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# poly kernel\n",
    "pipelines_poly_trained = train_pipelines(pipelines_poly, [train_1, train_1, train_1, train_1, train_1],\n",
    "                                    [y_Ca, y_P, y_Sand, y_SOC, y_pH])\n",
    "\n",
    "pipelines_poly_predictions = predictions(pipelines_poly_trained, [test_1, test_1, test_1, test_1, test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_Ca   = np.vstack([pipelines_rbf_predictions[0], pipelines_linear_predictions[0], pipelines_poly_predictions[0]]).T\n",
    "preds_P    = np.vstack([pipelines_rbf_predictions[1], pipelines_linear_predictions[1], pipelines_poly_predictions[1]]).T\n",
    "preds_Sand = np.vstack([pipelines_rbf_predictions[2], pipelines_linear_predictions[2], pipelines_poly_predictions[2]]).T\n",
    "preds_SOC  = np.vstack([pipelines_rbf_predictions[3], pipelines_linear_predictions[3], pipelines_poly_predictions[3]]).T\n",
    "preds_pH   = np.vstack([pipelines_rbf_predictions[4], pipelines_linear_predictions[4], pipelines_poly_predictions[4]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_pred_Ca   = preds_Ca[:, weights_Ca > 0].mean(axis=1)[:len(y_Ca)]\n",
    "balanced_pred_P    = preds_P[:, weights_P > 0].mean(axis=1)[:len(y_P)]\n",
    "balanced_pred_Sand = preds_Sand[:, weights_Sand > 0].mean(axis=1)[:len(y_Sand)]\n",
    "balanced_pred_SOC  = preds_SOC[:, weights_SOC > 0].mean(axis=1)[:len(y_SOC)]\n",
    "balanced_pred_pH   = preds_pH[:, weights_pH > 0].mean(axis=1)[:len(y_pH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub['Ca']   = balanced_pred_Ca\n",
    "sample_sub['P']    = balanced_pred_P\n",
    "sample_sub['pH']   = balanced_pred_pH\n",
    "sample_sub['SOC']  = balanced_pred_SOC\n",
    "sample_sub['Sand'] = balanced_pred_Sand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Public Leaderboard Score: 0.61319 , Private Leaderboard Score: 0.53293 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub.to_csv(os.path.join(basepath, 'submissions/dataset_1_svr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
